{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c58a492f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "97e4a365",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.5.5'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pyspark.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dbd4f0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2c2df29b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Picked up JAVA_TOOL_OPTIONS: -Djava.security.manager=allow\n",
      "Picked up JAVA_TOOL_OPTIONS: -Djava.security.manager=allow\n",
      "25/03/07 21:57:19 WARN Utils: Your hostname, Yes-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 192.168.18.79 instead (on interface en0)\n",
      "25/03/07 21:57:19 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/03/07 21:57:19 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "25/03/07 21:57:31 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .appName('test') \\\n",
    "    .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "60434125",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .parquet('fhv_tripdata_2021-01.parquet')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f30567",
   "metadata": {},
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "354618c9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampNTZType(), True), StructField('dropOff_datetime', TimestampNTZType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', IntegerType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0da7be38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   32645 fhv_tripdata_2021-01.parquet\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l fhv_tripdata_2021-01.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b7dd94c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "efe01265",
   "metadata": {},
   "outputs": [],
   "source": [
    "!head -n 101 fhv_tripdata_2021-01.parquet > head.parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d2f8a906",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     101 head.parquest\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l head.parquest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "06591b2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas = pd.read_parquet('fhv_tripdata_2021-01.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5ac48156",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset = df_pandas.head(101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "99a1f04d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subset.to_parquet('head.parquet', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "1d95dbc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_head = pd.read_parquet('head.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "691c3573",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dispatching_base_num              object\n",
       "pickup_datetime           datetime64[ns]\n",
       "dropOff_datetime          datetime64[ns]\n",
       "PUlocationID                     float64\n",
       "DOlocationID                     float64\n",
       "SR_Flag                           object\n",
       "Affiliated_base_number            object\n",
       "dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pandas_head.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f5db32e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pandas_head = df_pandas_head.astype(str)  # Convert all columns to string (or use specific dtypes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b77d7a4c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', StringType(), True), StructField('dropOff_datetime', StringType(), True), StructField('PUlocationID', StringType(), True), StructField('DOlocationID', StringType(), True), StructField('SR_Flag', StringType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.createDataFrame(df_pandas_head).schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b20b3888",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "5fedc256",
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "    types.StructField('dispatching_base_num', types.StringType(), True), \n",
    "    types.StructField('pickup_datetime', types.TimestampType(), True), \n",
    "    types.StructField('dropOff_datetime', types.TimestampType(), True), \n",
    "    types.StructField('PUlocationID', types.DoubleType(), True), \n",
    "    types.StructField('DOlocationID', types.DoubleType(), True), \n",
    "    types.StructField('SR_Flag', types.IntegerType(), True),\n",
    "    types.StructField('Affiliated_base_number', types.StringType(), True)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fb619dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema)\\\n",
    "    .parquet('fhv_tripdata_2021-01.parquet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8dd738f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 27), dropOff_datetime=datetime.datetime(2021, 1, 1, 8, 44), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00009', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 50), dropOff_datetime=datetime.datetime(2021, 1, 1, 9, 7), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00009'),\n",
       " Row(dispatching_base_num='B00013', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 1), dropOff_datetime=datetime.datetime(2021, 1, 1, 9, 51), PUlocationID=None, DOlocationID=None, SR_Flag=None, Affiliated_base_number='B00013'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 13, 9), dropOff_datetime=datetime.datetime(2021, 1, 1, 8, 21, 26), PUlocationID=None, DOlocationID=72.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 38, 31), dropOff_datetime=datetime.datetime(2021, 1, 1, 8, 53, 44), PUlocationID=None, DOlocationID=61.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 59, 2), dropOff_datetime=datetime.datetime(2021, 1, 1, 9, 8, 5), PUlocationID=None, DOlocationID=71.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 18, 12), dropOff_datetime=datetime.datetime(2021, 1, 1, 8, 30, 4), PUlocationID=None, DOlocationID=91.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 36, 15), dropOff_datetime=datetime.datetime(2021, 1, 1, 8, 45, 8), PUlocationID=None, DOlocationID=39.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 55, 4), dropOff_datetime=datetime.datetime(2021, 1, 1, 9, 13, 2), PUlocationID=None, DOlocationID=37.0, SR_Flag=None, Affiliated_base_number='B00037'),\n",
       " Row(dispatching_base_num='B00037', pickup_datetime=datetime.datetime(2021, 1, 1, 8, 48, 40), dropOff_datetime=datetime.datetime(2021, 1, 1, 9, 12, 2), PUlocationID=None, DOlocationID=39.0, SR_Flag=None, Affiliated_base_number='B00037')]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "b13d81ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "34e6b64f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/03/07 22:26:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/03/07 22:26:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/03/07 22:26:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/03/07 22:26:48 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 69.09% for 11 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 76.00% for 10 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 84.44% for 9 writers\n",
      "25/03/07 22:26:49 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f0bd5870",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.parquet('fhvhv/2021/01/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0b1abdbd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructType([StructField('dispatching_base_num', StringType(), True), StructField('pickup_datetime', TimestampType(), True), StructField('dropOff_datetime', TimestampType(), True), StructField('PUlocationID', DoubleType(), True), StructField('DOlocationID', DoubleType(), True), StructField('SR_Flag', IntegerType(), True), StructField('Affiliated_base_number', StringType(), True)])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c4358339",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- pickup_datetime: timestamp (nullable = true)\n",
      " |-- dropOff_datetime: timestamp (nullable = true)\n",
      " |-- PUlocationID: double (nullable = true)\n",
      " |-- DOlocationID: double (nullable = true)\n",
      " |-- SR_Flag: integer (nullable = true)\n",
      " |-- Affiliated_base_number: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4f3bd47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-------------------+------------+------------+\n",
      "|    pickup_datetime|   dropoff_datetime|PUlocationID|DOlocationID|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "|2021-01-29 16:58:23|2021-01-29 17:34:40|        NULL|        NULL|\n",
      "|2021-01-05 21:45:42|2021-01-05 21:57:16|        NULL|        72.0|\n",
      "|2021-01-15 08:35:51|2021-01-15 08:42:46|        NULL|       254.0|\n",
      "|2021-01-04 12:41:36|2021-01-04 12:46:44|        NULL|       197.0|\n",
      "|2021-01-08 21:11:33|2021-01-08 21:31:39|        NULL|        63.0|\n",
      "|2021-01-05 04:31:52|2021-01-05 04:38:10|        NULL|        61.0|\n",
      "|2021-01-11 23:57:45|2021-01-12 00:20:04|        NULL|       217.0|\n",
      "|2021-01-16 22:25:27|2021-01-16 22:30:22|        NULL|       140.0|\n",
      "|2021-01-26 13:11:11|2021-01-26 13:23:25|        NULL|        94.0|\n",
      "|2021-01-26 16:56:12|2021-01-26 17:08:37|        78.0|       250.0|\n",
      "|2021-01-29 18:27:42|2021-01-29 18:30:22|        NULL|        39.0|\n",
      "|2021-01-24 05:15:00|2021-01-24 05:34:00|       221.0|       115.0|\n",
      "|2021-01-17 04:30:00|2021-01-17 04:41:00|       221.0|       115.0|\n",
      "|2021-01-25 00:06:12|2021-01-25 00:22:40|        NULL|        32.0|\n",
      "|2021-01-26 14:51:12|2021-01-26 14:59:16|        NULL|        17.0|\n",
      "|2021-01-29 18:19:54|2021-01-29 18:28:31|        NULL|       213.0|\n",
      "|2021-01-26 18:04:27|2021-01-26 18:19:41|       210.0|       165.0|\n",
      "|2021-01-10 17:59:08|2021-01-10 18:10:23|        NULL|        74.0|\n",
      "|2021-01-09 04:09:22|2021-01-09 04:28:38|        NULL|       228.0|\n",
      "|2021-01-29 23:07:16|2021-01-30 00:18:25|        NULL|        71.0|\n",
      "+-------------------+-------------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PUlocationID', 'DOlocationID').show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
